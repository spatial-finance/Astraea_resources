{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from earthai.geo import reproject_on_the_fly\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable fiona driver\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in annotations\n",
    "df_annotations = pd.DataFrame()\n",
    "\n",
    "for path, subdirs, files in os.walk('Completed'):\n",
    "    for name in files:\n",
    "        if name.endswith(\".kml\"): \n",
    "            full_path = os.path.join(path, name)\n",
    "            name = full_path.split(\"/\")[-2]\n",
    "            plant = full_path.split(\"/\")[-1]\n",
    "            \n",
    "            # Read file\n",
    "            tmp = gpd.read_file(full_path, driver='KML')               \n",
    "            tmp['Processed By'] = name.strip()\n",
    "            tmp['uid'] = plant.split(\".\")[0].strip()\n",
    "\n",
    "            df_annotations = df_annotations.append(tmp, ignore_index=True)\n",
    "            \n",
    "# for path, subdirs, files in os.walk('Astraea to Review'):\n",
    "#     for name in files:\n",
    "#         if name.endswith(\".kml\"): \n",
    "#             full_path = os.path.join(path, name)\n",
    "#             name = full_path.split(\"/\")[-2]\n",
    "#             plant = full_path.split(\"/\")[-1]\n",
    "            \n",
    "#             # Read file\n",
    "#             tmp = gpd.read_file(full_path, driver='KML')               \n",
    "#             tmp['Processed By'] = name.strip()\n",
    "#             tmp['uid'] = plant.split(\".\")[0].strip()\n",
    "\n",
    "#             df_annotations = df_annotations.append(tmp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in statuses\n",
    "df_status = pd.DataFrame()\n",
    "\n",
    "sets=['Annotator 1', 'Annotator 2', 'Annotator 3']\n",
    "for s in sets:\n",
    "    tmp = pd.read_excel(\"cement_dataset_v4.1.xlsx\", sheet_name=s)\n",
    "    tmp = tmp[['uid','latitude','longitude','Date Processed','Processed By','status','notes']]\n",
    "    \n",
    "    df_status = df_status.append(tmp, ignore_index=True)\n",
    "    \n",
    "# convert to string\n",
    "df_status['Processed By'] = df_status['Processed By'].astype(str)\n",
    "df_status['uid'] = df_status['uid'].astype(str)\n",
    "\n",
    "# to lower case\n",
    "df_status['Processed By'] = df_status['Processed By'].str.lower()\n",
    "\n",
    "# remove any leading/trailing spaces\n",
    "df_status['uid'] = df_status['uid'].str.strip()\n",
    "df_status['Processed By'] = df_status['Processed By'].str.strip()\n",
    "\n",
    "# fix status\n",
    "df_status.status = df_status.status.fillna('')\n",
    "df_status.status = df_status.status.str.lower()\n",
    "df_status.status = df_status.status.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if merge worked\n",
    "df = pd.merge(df_status, df_annotations, how='outer', left_on=['uid', 'Processed By'], right_on=['uid', 'Processed By'], indicator=True)\n",
    "\n",
    "# df._merge.value_counts()\n",
    "# df[df._merge == 'both']['Processed By'].value_counts()\n",
    "# df[df._merge == 'right_only']['Processed By'].value_counts()\n",
    "# df[df._merge == 'left_only']['Processed By'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benice wairimu ruga          2972\n",
       "marvin mwangi                2910\n",
       "john oduor otieno            2695\n",
       "maina lawrence irungu        2644\n",
       "isaack odhiambo otieno       2431\n",
       "caroline kioko               2286\n",
       "vincent kipngetich           2134\n",
       "fiona atieno                 2050\n",
       "rasoa simiyu                 1915\n",
       "njoki muriithi               1609\n",
       "regina wanjala nyambu        1545\n",
       "emily nyawira waithera       1381\n",
       "clement omunga               1354\n",
       "ephantus maina               1011\n",
       "erick karanja                 963\n",
       "damaris kwamboka okenyuri     962\n",
       "moses njau                    955\n",
       "joshua gichuki mwangi         657\n",
       "solomon gitahi gachure        293\n",
       "Name: Processed By, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df._merge == 'both']['Processed By'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Processed By, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df._merge == 'right_only']['Processed By'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isaack odhiambo otieno       116\n",
       "joshua gichuki mwangi         31\n",
       "rasoa simiyu                  22\n",
       "maina lawrence irungu         22\n",
       "njoki muriithi                11\n",
       "caroline kioko                11\n",
       "solomon gitahi gachure        10\n",
       "john oduor otieno              9\n",
       "fiona atieno                   9\n",
       "erick karanja                  6\n",
       "marvin mwangi                  6\n",
       "moses njau                     5\n",
       "clement omunga                 5\n",
       "benice wairimu ruga            5\n",
       "regina wanjala nyambu          4\n",
       "nan                            3\n",
       "vincent kipngetich             3\n",
       "damaris kwamboka okenyuri      2\n",
       "ephantus maina                 1\n",
       "emily nyawira waithera         1\n",
       "Name: Processed By, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df._merge == 'left_only']['Processed By'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no issues</td>\n",
       "      <td>7408</td>\n",
       "      <td>87.803722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kiln under a cover</td>\n",
       "      <td>561</td>\n",
       "      <td>6.649283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plant under construction</td>\n",
       "      <td>148</td>\n",
       "      <td>1.754178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiln is blocked</td>\n",
       "      <td>136</td>\n",
       "      <td>1.611947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unclear imagery</td>\n",
       "      <td>95</td>\n",
       "      <td>1.125993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plant not found</td>\n",
       "      <td>50</td>\n",
       "      <td>0.592628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>duplicate plant</td>\n",
       "      <td>28</td>\n",
       "      <td>0.331872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cloudy imagery</td>\n",
       "      <td>7</td>\n",
       "      <td>0.082968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no imagery</td>\n",
       "      <td>4</td>\n",
       "      <td>0.047410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/markdown": [
       "|    | status                   |   count |    percent |\n",
       "|---:|:-------------------------|--------:|-----------:|\n",
       "|  0 | no issues                |    7408 | 87.8037    |\n",
       "|  1 | kiln under a cover       |     561 |  6.64928   |\n",
       "|  2 | plant under construction |     148 |  1.75418   |\n",
       "|  3 | kiln is blocked          |     136 |  1.61195   |\n",
       "|  4 | unclear imagery          |      95 |  1.12599   |\n",
       "|  5 | plant not found          |      50 |  0.592628  |\n",
       "|  6 | duplicate plant          |      28 |  0.331872  |\n",
       "|  7 | cloudy imagery           |       7 |  0.0829679 |\n",
       "|  8 | no imagery               |       4 |  0.0474102 |"
      ],
      "text/plain": [
       "                     status  count    percent\n",
       "0                 no issues   7408  87.803722\n",
       "1        kiln under a cover    561   6.649283\n",
       "2  plant under construction    148   1.754178\n",
       "3           kiln is blocked    136   1.611947\n",
       "4           unclear imagery     95   1.125993\n",
       "5           plant not found     50   0.592628\n",
       "6           duplicate plant     28   0.331872\n",
       "7            cloudy imagery      7   0.082968\n",
       "8                no imagery      4   0.047410"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_status_count = df_status.status.value_counts().reset_index()\n",
    "df_status_count.columns = ['status', 'count']\n",
    "df_status_count['percent'] = (df_status_count['count'] / df_status_count['count'].sum())*100\n",
    "df_status_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join annotations and statuses\n",
    "df = pd.merge(df_status, df_annotations, how='left', left_on=['uid', 'Processed By'], right_on=['uid', 'Processed By'])\n",
    "\n",
    "# drop duplicates in case annotator accidentally exported the same annotation twice\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Acquisition_Date'] = pd.to_datetime(df.Description, errors='coerce')\n",
    "df['Acquisition_Year'] = df['Acquisition_Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.018426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2002</td>\n",
       "      <td>24</td>\n",
       "      <td>0.073706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>0.033782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>131</td>\n",
       "      <td>0.402309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>0.033782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>32</td>\n",
       "      <td>0.098274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>0.042995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2008</td>\n",
       "      <td>35</td>\n",
       "      <td>0.107487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2009</td>\n",
       "      <td>164</td>\n",
       "      <td>0.503655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010</td>\n",
       "      <td>250</td>\n",
       "      <td>0.767766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>328</td>\n",
       "      <td>1.007309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012</td>\n",
       "      <td>341</td>\n",
       "      <td>1.047233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>620</td>\n",
       "      <td>1.904060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>1193</td>\n",
       "      <td>3.663780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>1324</td>\n",
       "      <td>4.066089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1996</td>\n",
       "      <td>6.129845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>3493</td>\n",
       "      <td>10.727228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>5514</td>\n",
       "      <td>16.933849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>7223</td>\n",
       "      <td>22.182298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>9531</td>\n",
       "      <td>29.270315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021</td>\n",
       "      <td>317</td>\n",
       "      <td>0.973527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/markdown": [
       "|    |   year |   count |     percent |\n",
       "|---:|-------:|--------:|------------:|\n",
       "| 20 |   2000 |       6 |  0.0184264  |\n",
       "| 21 |   2001 |       2 |  0.00614213 |\n",
       "| 16 |   2002 |      24 |  0.0737055  |\n",
       "| 19 |   2003 |      11 |  0.0337817  |\n",
       "| 13 |   2004 |     131 |  0.402309   |\n",
       "| 18 |   2005 |      11 |  0.0337817  |\n",
       "| 15 |   2006 |      32 |  0.0982741  |\n",
       "| 17 |   2007 |      14 |  0.0429949  |\n",
       "| 14 |   2008 |      35 |  0.107487   |\n",
       "| 12 |   2009 |     164 |  0.503655   |\n",
       "| 11 |   2010 |     250 |  0.767766   |\n",
       "|  9 |   2011 |     328 |  1.00731    |\n",
       "|  8 |   2012 |     341 |  1.04723    |\n",
       "|  7 |   2013 |     620 |  1.90406    |\n",
       "|  6 |   2014 |    1193 |  3.66378    |\n",
       "|  5 |   2015 |    1324 |  4.06609    |\n",
       "|  4 |   2016 |    1996 |  6.12984    |\n",
       "|  3 |   2017 |    3493 | 10.7272     |\n",
       "|  2 |   2018 |    5514 | 16.9338     |\n",
       "|  1 |   2019 |    7223 | 22.1823     |\n",
       "|  0 |   2020 |    9531 | 29.2703     |\n",
       "| 10 |   2021 |     317 |  0.973527   |\n",
       "| 22 |   2027 |       1 |  0.00307106 |\n",
       "| 23 |   2105 |       1 |  0.00307106 |"
      ],
      "text/plain": [
       "    year  count    percent\n",
       "20  2000      6   0.018426\n",
       "21  2001      2   0.006142\n",
       "16  2002     24   0.073706\n",
       "19  2003     11   0.033782\n",
       "13  2004    131   0.402309\n",
       "18  2005     11   0.033782\n",
       "15  2006     32   0.098274\n",
       "17  2007     14   0.042995\n",
       "14  2008     35   0.107487\n",
       "12  2009    164   0.503655\n",
       "11  2010    250   0.767766\n",
       "9   2011    328   1.007309\n",
       "8   2012    341   1.047233\n",
       "7   2013    620   1.904060\n",
       "6   2014   1193   3.663780\n",
       "5   2015   1324   4.066089\n",
       "4   2016   1996   6.129845\n",
       "3   2017   3493  10.727228\n",
       "2   2018   5514  16.933849\n",
       "1   2019   7223  22.182298\n",
       "0   2020   9531  29.270315\n",
       "10  2021    317   0.973527\n",
       "22  2027      1   0.003071\n",
       "23  2105      1   0.003071"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_year_count = df.Acquisition_Year.value_counts().reset_index()\n",
    "df_year_count.columns = ['year', 'count']\n",
    "df_year_count['percent'] = (df_year_count['count'] / df_year_count['count'].sum())*100\n",
    "df_year_count['year'] = df_year_count['year'].astype(int)\n",
    "df_year_count = df_year_count[(df_year_count.year != 2026) & (df_year_count.year != 2107)]\n",
    "df_year_count.sort_values('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_annotation_quality(group):\n",
    "    # add geometry type (point, linestring, polygon)\n",
    "    group['geom_type'] = group.geometry.apply(lambda x: x.type)\n",
    "    \n",
    "    s = \"\"\n",
    "    \n",
    "    # check polygon if missing\n",
    "    if len(group[group.geom_type == 'Polygon']) == 0:\n",
    "        s += \"Polygon is missing; \"\n",
    "    # check if multiple polygons\n",
    "    elif len(group[group.geom_type == 'Polygon']) > 1:\n",
    "        s += \"Multiple polygons annotated; \"\n",
    "        \n",
    "    # check number of linestrings for each kiln\n",
    "    grouped2 = group[group.geom_type == 'LineString'].groupby(['uid', 'Processed By', 'Name'])\n",
    "    for name2, group2 in grouped2:\n",
    "        # check if missing measurement\n",
    "        if len(group2) < 2:\n",
    "            s += \"Length or width of kiln {} is missing; \".format(name2[2])\n",
    "        # check if too many measurements\n",
    "        elif len(group2) > 2:\n",
    "            s += \"More than 2 line measurements for kiln {}; \".format(name2[2])\n",
    "            \n",
    "    # check acquisition dates\n",
    "    for idx, row in group.iterrows():\n",
    "        if pd.notnull(row.Acquisition_Date):\n",
    "            if row.Acquisition_Date.year < 1900 or row.Acquisition_Date.year > 2021:\n",
    "                s += \"Date format is incorrect on one of annotations; \"\n",
    "            \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous feedback\n",
    "!rm -r Completed/*\n",
    "!rm -r CloudFactory\\ to\\ Review/*\n",
    "!rm Completed.tar.gz\n",
    "!rm CloudFactory\\ to\\ Review.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have all the annotations\n",
    "grouped = df.groupby(['uid'])\n",
    "results_df = pd.DataFrame(columns=['uid', 'annotator1', 'issues1', 'annotator2', 'issues2', 'annotator3', 'issues3'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    \n",
    "    res_dict = {}\n",
    "    res_dict['uid'] = name    \n",
    "    \n",
    "    grouped2 = group.groupby(['uid', 'Processed By', 'status'])\n",
    "    idx = 1\n",
    "    for name2, group2 in grouped2:\n",
    "        if len(group2[group2.Name.notnull()]) == 2811:\n",
    "            s = \"Excel file needs to be removed from output\"\n",
    "        elif name2[2].strip() == '':\n",
    "            s = \"Status is missing\"\n",
    "        elif name2[2] == 'no issues':\n",
    "            if len(group2[group2.Name.notnull()]) == 0:\n",
    "                s = \"Annotations are missing\"\n",
    "            else:\n",
    "                s = check_annotation_quality(group2)\n",
    "        else:\n",
    "            s = ''\n",
    "        res_dict['annotator{}'.format(idx)] = name2[1] \n",
    "        res_dict['issues{}'.format(idx)] = s \n",
    "        idx += 1\n",
    "        \n",
    "        tmp = df_annotations[(df_annotations[\"Processed By\"] == name2[1]) & (df_annotations.uid == name)]\n",
    "        \n",
    "        if name2[1] != 'nan':\n",
    "            if not os.path.isdir('Completed/{}'.format(name2[1])):\n",
    "                os.mkdir('Completed/{}'.format(name2[1])) \n",
    "                os.mkdir('CloudFactory to Review/{}'.format(name2[1])) \n",
    "\n",
    "            if len(tmp) > 0:\n",
    "                if s == '':\n",
    "                    with fiona.drivers():\n",
    "                        tmp.to_file('Completed/{}/{}.kml'.format(name2[1], name), driver='KML')\n",
    "                else:\n",
    "                    with fiona.drivers():\n",
    "                        tmp.to_file('CloudFactory to Review/{}/{}.kml'.format(name2[1], name), driver='KML')\n",
    "                        \n",
    "    results_df = results_df.append(res_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overall(row):\n",
    "    num_issues = 0\n",
    "    if row.issues1 != '':\n",
    "        num_issues += 1\n",
    "    if row.issues2 != '':\n",
    "        num_issues += 1\n",
    "    if row.issues3 != '':\n",
    "        num_issues += 1\n",
    "    return 3 - num_issues\n",
    "\n",
    "results_df['num_completed'] = results_df.apply(check_overall,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl as pxl\n",
    "\n",
    "excel_book = pxl.load_workbook(\"cement_dataset_v4.1.xlsx\")\n",
    "with pd.ExcelWriter(\"cement_dataset_v4.1.xlsx\", engine='openpyxl') as writer:\n",
    "    writer.book = excel_book\n",
    "    writer.sheets = {\n",
    "        worksheet.title: worksheet\n",
    "        for worksheet in excel_book.worksheets\n",
    "    }\n",
    "    results_df.to_excel(writer, 'Feedback', index=False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Go back and fix above labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -czvf \"CloudFactory to Review.tar.gz\" \"CloudFactory to Review/\"\n",
    "!tar -czvf Completed.tar.gz Completed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EarthAI Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
