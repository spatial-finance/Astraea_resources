{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to ensure data type consistency of image chips between model build and model deployment workflows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai==1.0.61 in /opt/conda/envs/earthai/lib/python3.7/site-packages (1.0.61)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (5.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (1.5.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (4.9.1)\n",
      "Requirement already satisfied: bottleneck in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (1.3.2)\n",
      "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (2.3.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (7.2.0)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (7.352.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (1.19.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (0.7.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (1.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (2.24.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (20.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (1.6.0)\n",
      "Requirement already satisfied: numexpr in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (2.7.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (1.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/earthai/lib/python3.7/site-packages (from fastai==1.0.61) (3.3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from beautifulsoup4->fastai==1.0.61) (2.0.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.8.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (2.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (4.49.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (49.6.0.post20200814)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (7.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from requests->fastai==1.0.61) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from requests->fastai==1.0.61) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from requests->fastai==1.0.61) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from requests->fastai==1.0.61) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from packaging->fastai==1.0.61) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/envs/earthai/lib/python3.7/site-packages (from packaging->fastai==1.0.61) (1.15.0)\n",
      "Requirement already satisfied: future in /home/jovyan/.local/lib/python3.7/site-packages (from torch>=1.0.0->fastai==1.0.61) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from pandas->fastai==1.0.61) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from pandas->fastai==1.0.61) (2020.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from matplotlib->fastai==1.0.61) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from matplotlib->fastai==1.0.61) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/envs/earthai/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/earthai/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai==1.0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.widgets import ClassConfusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download .tar File of Chips From S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_SOURCE_PATH = 'L8-TIR-macro-localization-model-build3'\n",
    "TARGET_PATH = '/scratch/ALD_L8_TIR_chips_v4p1_train3'\n",
    "IMG_DIR = 'ALD_L8_TIR_steel_chips_v4p1_2020_train3'\n",
    "\n",
    "!mkdir -p {TARGET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('sfi-shared-assets')\n",
    "\n",
    "bucket.download_file(str(Path(AWS_SOURCE_PATH, IMG_DIR+'.tar')), \n",
    "                     str(Path(TARGET_PATH, IMG_DIR+'.tar')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {TARGET_PATH} && tar xf {str(Path(IMG_DIR+'.tar'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Sample GeoTIFF, Open with Rasterio, Check Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHN0104_steel_v4p1_2020_L8_TIR.tif'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tif_list = os.listdir(Path(TARGET_PATH, IMG_DIR))\n",
    "tif_file = tif_list[0]\n",
    "tif_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF\n",
      "-------\n",
      "Numpy object:  <class 'numpy.ndarray'>\n",
      "Data type:  uint16\n",
      "Size of numpy object:  (3, 35, 35)\n",
      "Minimum of numpy array:  [0 0 0]\n",
      "Maximum of numpy array:  [65535 65535 65535]\n"
     ]
    }
   ],
   "source": [
    "infile = rasterio.open(Path(TARGET_PATH, IMG_DIR, tif_file))\n",
    "raster = infile.read()\n",
    "print('GeoTIFF')\n",
    "print('-------')\n",
    "print('Numpy object: ', type(raster))\n",
    "print('Data type: ', raster.dtype)\n",
    "print('Size of numpy object: ', raster.shape)\n",
    "print('Minimum of numpy array: ', raster.min(axis=(1,2)))\n",
    "print('Maximum of numpy array: ', raster.max(axis=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write GeoTiff to PNG, Open PNG, Check Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_file = tif_file.replace('.tif', '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = infile.profile\n",
    "profile['driver'] = 'PNG'\n",
    "\n",
    "with rasterio.open(Path(TARGET_PATH, IMG_DIR, png_file), 'w', **profile) as dst:\n",
    "    dst.write(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG\n",
      "-------\n",
      "Numpy object:  <class 'numpy.ndarray'>\n",
      "Data type:  uint16\n",
      "Size of numpy object:  (3, 35, 35)\n",
      "Minimum of numpy array:  [0 0 0]\n",
      "Maximum of numpy array:  [65535 65535 65535]\n"
     ]
    }
   ],
   "source": [
    "infile2 = rasterio.open(Path(TARGET_PATH, IMG_DIR, png_file))\n",
    "raster2 = infile2.read()\n",
    "print('PNG')\n",
    "print('-------')\n",
    "print('Numpy object: ', type(raster2))\n",
    "print('Data type: ', raster2.dtype)\n",
    "print('Size of numpy object: ', raster2.shape)\n",
    "print('Minimum of numpy array: ', raster2.min(axis=(1,2)))\n",
    "print('Maximum of numpy array: ', raster2.max(axis=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/ALD_L8_TIR_chips_v4p1_train3/ALD_L8_TIR_steel_chips_v4p1_2020_train3/train/CHN0104_steel_v4p1_2020_L8_TIR.png')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.mkdir(Path(TARGET_PATH, IMG_DIR, 'train'))\n",
    "shutil.move(Path(TARGET_PATH, IMG_DIR, png_file), Path(TARGET_PATH, IMG_DIR, 'train', png_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    }
   ],
   "source": [
    "tfms = get_transforms(do_flip=True,\n",
    "                      flip_vert=True, \n",
    "                      max_lighting=None, \n",
    "                      max_zoom=1.5, \n",
    "                      max_warp=0.2)\n",
    "\n",
    "data = (ImageDataBunch.from_folder(Path(TARGET_PATH, IMG_DIR), train='train', valid='validate', \n",
    "                                   ds_tfms=tfms, bs=16, num_workers=0, seed=42)\n",
    "        .normalize(imagenet_stats))\n",
    "raster3 = data.x[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastai\n",
      "------\n",
      "Object type:  <class 'torch.Tensor'>\n",
      "Data type: torch.float32\n",
      "Size:  torch.Size([3, 35, 35])\n",
      "Image minimum: torch.return_types.min(\n",
      "values=tensor([[0.2039, 0.2235, 0.2353,  ..., 0.0314, 0.0235, 0.0902],\n",
      "        [0.1882, 0.2078, 0.2235,  ..., 0.0275, 0.0353, 0.1373],\n",
      "        [0.1804, 0.2000, 0.2196,  ..., 0.0431, 0.0667, 0.1843],\n",
      "        ...,\n",
      "        [0.3882, 0.3451, 0.2941,  ..., 0.4627, 0.3882, 0.3176],\n",
      "        [0.2745, 0.2314, 0.2000,  ..., 0.3686, 0.3176, 0.2627],\n",
      "        [0.2196, 0.1882, 0.1843,  ..., 0.2667, 0.2353, 0.1961]]),\n",
      "indices=tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [2, 1, 1,  ..., 2, 2, 2],\n",
      "        [1, 1, 1,  ..., 2, 2, 2],\n",
      "        [1, 0, 1,  ..., 2, 0, 0]]))\n",
      "Image maximum: torch.return_types.max(\n",
      "values=tensor([[0.3804, 0.3843, 0.3725,  ..., 0.1804, 0.1686, 0.2235],\n",
      "        [0.3647, 0.3725, 0.3569,  ..., 0.1804, 0.2078, 0.2784],\n",
      "        [0.3529, 0.3608, 0.3490,  ..., 0.1686, 0.2588, 0.3333],\n",
      "        ...,\n",
      "        [0.4196, 0.3882, 0.3725,  ..., 0.5843, 0.5216, 0.4588],\n",
      "        [0.3412, 0.3255, 0.3294,  ..., 0.4745, 0.4000, 0.3412],\n",
      "        [0.3176, 0.3176, 0.3294,  ..., 0.3647, 0.2902, 0.2275]]),\n",
      "indices=tensor([[2, 2, 2,  ..., 2, 1, 1],\n",
      "        [2, 2, 2,  ..., 2, 1, 1],\n",
      "        [2, 2, 2,  ..., 2, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [2, 2, 2,  ..., 1, 1, 1],\n",
      "        [2, 2, 2,  ..., 1, 1, 1]]))\n",
      "Image mean:  tensor([[0.2758, 0.2915, 0.2980,  ..., 0.1059, 0.1190, 0.1647],\n",
      "        [0.2654, 0.2810, 0.2837,  ..., 0.1046, 0.1399, 0.2118],\n",
      "        [0.2601, 0.2784, 0.2824,  ..., 0.1124, 0.1686, 0.2575],\n",
      "        ...,\n",
      "        [0.4000, 0.3608, 0.3333,  ..., 0.5255, 0.4575, 0.3922],\n",
      "        [0.3098, 0.2719, 0.2706,  ..., 0.4170, 0.3595, 0.3046],\n",
      "        [0.2549, 0.2353, 0.2497,  ..., 0.3033, 0.2562, 0.2118]])\n",
      "Image standard deviation:  tensor([[0.0927, 0.0832, 0.0694,  ..., 0.0745, 0.0827, 0.0680],\n",
      "        [0.0903, 0.0839, 0.0676,  ..., 0.0765, 0.0919, 0.0709],\n",
      "        [0.0870, 0.0805, 0.0648,  ..., 0.0638, 0.0966, 0.0745],\n",
      "        ...,\n",
      "        [0.0171, 0.0239, 0.0392,  ..., 0.0609, 0.0668, 0.0709],\n",
      "        [0.0335, 0.0484, 0.0655,  ..., 0.0535, 0.0412, 0.0395],\n",
      "        [0.0545, 0.0716, 0.0736,  ..., 0.0535, 0.0297, 0.0157]])\n",
      "Data:  tensor([[[0.2431, 0.2667, 0.2863,  ..., 0.0314, 0.0235, 0.0902],\n",
      "         [0.2431, 0.2627, 0.2706,  ..., 0.0275, 0.0353, 0.1373],\n",
      "         [0.2471, 0.2745, 0.2784,  ..., 0.0431, 0.0667, 0.1843],\n",
      "         ...,\n",
      "         [0.4196, 0.3882, 0.3725,  ..., 0.5294, 0.4627, 0.4000],\n",
      "         [0.3137, 0.2588, 0.2824,  ..., 0.4078, 0.3608, 0.3098],\n",
      "         [0.2275, 0.1882, 0.2353,  ..., 0.2784, 0.2353, 0.1961]],\n",
      "\n",
      "        [[0.2039, 0.2235, 0.2353,  ..., 0.1059, 0.1686, 0.2235],\n",
      "         [0.1882, 0.2078, 0.2235,  ..., 0.1059, 0.2078, 0.2784],\n",
      "         [0.1804, 0.2000, 0.2196,  ..., 0.1255, 0.2588, 0.3333],\n",
      "         ...,\n",
      "         [0.3922, 0.3451, 0.2941,  ..., 0.5843, 0.5216, 0.4588],\n",
      "         [0.2745, 0.2314, 0.2000,  ..., 0.4745, 0.4000, 0.3412],\n",
      "         [0.2196, 0.2000, 0.1843,  ..., 0.3647, 0.2902, 0.2275]],\n",
      "\n",
      "        [[0.3804, 0.3843, 0.3725,  ..., 0.1804, 0.1647, 0.1804],\n",
      "         [0.3647, 0.3725, 0.3569,  ..., 0.1804, 0.1765, 0.2196],\n",
      "         [0.3529, 0.3608, 0.3490,  ..., 0.1686, 0.1804, 0.2549],\n",
      "         ...,\n",
      "         [0.3882, 0.3490, 0.3333,  ..., 0.4627, 0.3882, 0.3176],\n",
      "         [0.3412, 0.3255, 0.3294,  ..., 0.3686, 0.3176, 0.2627],\n",
      "         [0.3176, 0.3176, 0.3294,  ..., 0.2667, 0.2431, 0.2118]]])\n"
     ]
    }
   ],
   "source": [
    "print('Fastai')\n",
    "print('------')\n",
    "print('Object type: ', type(raster3))\n",
    "print('Data type:', raster3.dtype)\n",
    "print('Size: ', raster3.shape)\n",
    "print('Image minimum:', raster3.min(0))\n",
    "print('Image maximum:', raster3.max(0))\n",
    "print('Image mean: ', raster3.mean(0))\n",
    "print('Image standard deviation: ', np.sqrt(raster3.var(0)))\n",
    "print('Data: ', raster3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster4 = torch.from_numpy(raster2.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion test\n",
      "------\n",
      "Object type:  <class 'torch.Tensor'>\n",
      "Data type: torch.float32\n",
      "Size:  torch.Size([3, 35, 35])\n",
      "Image minimum: tensor(0.)\n",
      "Image maximum: tensor(65535.)\n",
      "Image mean:  tensor(23198.9355)\n",
      "Image standard deviation:  tensor(15612.5215)\n",
      "Data:  tensor([[[16104., 17539., 18735.,  ...,  2232.,  1753.,  6019.],\n",
      "         [15945., 17300., 17818.,  ...,  1833.,  2351.,  9009.],\n",
      "         [16383., 17978., 18257.,  ...,  2910.,  4504., 12198.],\n",
      "         ...,\n",
      "         [27505., 25552., 24515.,  ..., 34601., 30415., 26269.],\n",
      "         [20649., 17101., 18616.,  ..., 26668., 23559., 20330.],\n",
      "         [15028., 12357., 15387.,  ..., 18416., 15586., 12995.]],\n",
      "\n",
      "        [[13350., 14679., 15471.,  ...,  6929., 11257., 14679.],\n",
      "         [12445., 13802., 14792.,  ...,  7071., 13576., 18300.],\n",
      "         [11822., 13208., 14566.,  ...,  8428., 16998., 21948.],\n",
      "         ...,\n",
      "         [25682., 22684., 19431.,  ..., 38381., 34082., 30179.],\n",
      "         [18130., 15217., 13265.,  ..., 31056., 26276., 22429.],\n",
      "         [14509., 13095., 12134.,  ..., 24041., 18950., 14877.]],\n",
      "\n",
      "        [[25062., 25205., 24529.,  ..., 11967., 10881., 11906.],\n",
      "         [24037., 24324., 23484.,  ..., 11967., 11619., 14488.],\n",
      "         [23095., 23627., 23033.,  ..., 11065., 11865., 16701.],\n",
      "         ...,\n",
      "         [25410., 22951., 21947.,  ..., 30246., 25410., 20984.],\n",
      "         [22275., 21496., 21722.,  ..., 24263., 20984., 17316.],\n",
      "         [20984., 20779., 21640.,  ..., 17623., 15922., 13975.]]])\n"
     ]
    }
   ],
   "source": [
    "print('Conversion test')\n",
    "print('------')\n",
    "print('Object type: ', type(raster4))\n",
    "print('Data type:', raster4.dtype)\n",
    "print('Size: ', raster4.shape)\n",
    "print('Image minimum:', raster4.min())\n",
    "print('Image maximum:', raster4.max())\n",
    "print('Image mean: ', raster4.mean())\n",
    "print('Image standard deviation: ', np.sqrt(raster4.var()))\n",
    "print('Data: ', raster4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster5 = raster4 / (raster4.max() - raster4.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion test\n",
      "------\n",
      "Object type:  <class 'torch.Tensor'>\n",
      "Data type: torch.float32\n",
      "Size:  torch.Size([3, 35, 35])\n",
      "Image minimum: tensor(0.)\n",
      "Image maximum: tensor(1.)\n",
      "Image mean:  tensor(0.3540)\n",
      "Image standard deviation:  tensor(0.2382)\n",
      "Data:  tensor([[[0.2457, 0.2676, 0.2859,  ..., 0.0341, 0.0267, 0.0918],\n",
      "         [0.2433, 0.2640, 0.2719,  ..., 0.0280, 0.0359, 0.1375],\n",
      "         [0.2500, 0.2743, 0.2786,  ..., 0.0444, 0.0687, 0.1861],\n",
      "         ...,\n",
      "         [0.4197, 0.3899, 0.3741,  ..., 0.5280, 0.4641, 0.4008],\n",
      "         [0.3151, 0.2609, 0.2841,  ..., 0.4069, 0.3595, 0.3102],\n",
      "         [0.2293, 0.1886, 0.2348,  ..., 0.2810, 0.2378, 0.1983]],\n",
      "\n",
      "        [[0.2037, 0.2240, 0.2361,  ..., 0.1057, 0.1718, 0.2240],\n",
      "         [0.1899, 0.2106, 0.2257,  ..., 0.1079, 0.2072, 0.2792],\n",
      "         [0.1804, 0.2015, 0.2223,  ..., 0.1286, 0.2594, 0.3349],\n",
      "         ...,\n",
      "         [0.3919, 0.3461, 0.2965,  ..., 0.5857, 0.5201, 0.4605],\n",
      "         [0.2766, 0.2322, 0.2024,  ..., 0.4739, 0.4009, 0.3422],\n",
      "         [0.2214, 0.1998, 0.1852,  ..., 0.3668, 0.2892, 0.2270]],\n",
      "\n",
      "        [[0.3824, 0.3846, 0.3743,  ..., 0.1826, 0.1660, 0.1817],\n",
      "         [0.3668, 0.3712, 0.3583,  ..., 0.1826, 0.1773, 0.2211],\n",
      "         [0.3524, 0.3605, 0.3515,  ..., 0.1688, 0.1810, 0.2548],\n",
      "         ...,\n",
      "         [0.3877, 0.3502, 0.3349,  ..., 0.4615, 0.3877, 0.3202],\n",
      "         [0.3399, 0.3280, 0.3315,  ..., 0.3702, 0.3202, 0.2642],\n",
      "         [0.3202, 0.3171, 0.3302,  ..., 0.2689, 0.2430, 0.2132]]])\n"
     ]
    }
   ],
   "source": [
    "print('Conversion test 2')\n",
    "print('------')\n",
    "print('Object type: ', type(raster5))\n",
    "print('Data type:', raster5.dtype)\n",
    "print('Size: ', raster5.shape)\n",
    "print('Image minimum:', raster5.min())\n",
    "print('Image maximum:', raster5.max())\n",
    "print('Image mean: ', raster5.mean())\n",
    "print('Image standard deviation: ', np.sqrt(raster5.var()))\n",
    "print('Data: ', raster5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EarthAI Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
