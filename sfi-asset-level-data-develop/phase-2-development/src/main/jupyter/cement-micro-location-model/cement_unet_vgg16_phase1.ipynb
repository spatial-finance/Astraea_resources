{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "qLGkt5qiyz4E",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Cement Micro-localization Model - WP 2.1a (Phase 1)\n",
    "\n",
    "This notebook is a modified version of the model build completed for WP 2.1a in Phase 1 of the SFI/ALD project. It has been modified to run within EarthAI Notebook. The only change is that instead of reading image chips from a Google Drive folder, it copies them from the shared SFI/ALD AWS S3 bucket to fast local storage in EarthAI Notebook for training the deep learning model.\n",
    "\n",
    "Input chips for training deep learning model:\n",
    "* 1024x1024x3 RGB images for training in jpeg format: s3://sfi-shared-assets/cement-microloc-phase1/images/data/\n",
    "* 1024x1024 binary masks in jpeg format: s3://sfi-shared-assets/cement-microloc-phase1/CIFF-ALD/masks/data/\n",
    "* 1024x1024x3 RGB images for testing in jpeg format: s3://sfi-shared-assets/cement-microloc-phase1/CIFF-ALD/test/\n",
    "\n",
    "Outputs:\n",
    "* Model: s3://sfi-shared-assets/cement-microloc-phase1/model/cement_model.h5\n",
    "* Plots: s3://sfi-shared-assets/cement-microloc-phase1/plots/\n",
    "\n",
    "Attribution for original source code:\n",
    "Steven Reece (reece@robots.ox.ac.uk)\n",
    "Version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "iAve6DCL4JH4",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "from tensorflow.keras.backend import epsilon, clip\n",
    "from tensorflow.keras import layers, models\n",
    "#from google.colab import drive\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "#drive.mount('/content/drive/')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "L9YmGQBQPrdn",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "NBANDS = 3 # RGB imagery\n",
    "IMG_WIDTH = 1024\n",
    "IMG_HEIGHT = 1024\n",
    "INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, NBANDS)\n",
    "\n",
    "# Encoder\n",
    "vgg = tf.keras.applications.VGG16(input_shape=INPUT_SHAPE, weights='imagenet',include_top=False)\n",
    "vgg.trainable = False\n",
    "\n",
    "c1 = vgg.get_layer('block1_conv2').output\n",
    "c2 = vgg.get_layer('block2_conv2').output\n",
    "c3 = vgg.get_layer('block3_conv2').output\n",
    "c4 = vgg.get_layer('block4_conv2').output\n",
    "cv = vgg.get_layer('block5_conv2').output\n",
    "\n",
    "# Decoder\n",
    "u5 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(cv)\n",
    "u5 = tf.keras.layers.concatenate([u5, c4])\n",
    "c5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u5)\n",
    "c5 = tf.keras.layers.Dropout(0.2)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c3])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c2])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c1])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c8)\n",
    "\n",
    "model = models.Model(vgg.input,output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "WYm61fCN_jZu",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a weighted categorical cross-entropy cost function\n",
    "\n",
    "def custom_accuracy_p(y_true,y_pred):\n",
    "# True positive rate\n",
    "  sh=tf.shape(y_pred)\n",
    "  nvals=tf.size(y_pred)\n",
    "\n",
    "  y_pred = tf.reshape(y_pred, [nvals,1])\n",
    "  y_true = tf.reshape(y_true, [nvals,1])\n",
    "\n",
    "  n_y_true = tf.reduce_sum(y_true)\n",
    "  \n",
    "  return tf.divide(tf.reduce_sum(tf.multiply(y_true,y_pred)),tf.maximum(epsilon(),n_y_true))\n",
    "\n",
    "def custom_accuracy_n(y_true,y_pred):\n",
    "# True negative rate\n",
    "  sh=tf.shape(y_pred)\n",
    "  nvals=tf.size(y_pred)\n",
    "\n",
    "  y_pred = tf.reshape(y_pred, [nvals,1])\n",
    "  y_true = tf.reshape(y_true, [nvals,1])\n",
    "  \n",
    "  n_y_false = tf.reduce_sum(1.0-y_true)\n",
    "\n",
    "  return tf.divide(tf.reduce_sum(tf.multiply(1.0-y_true[:,0],1.0-y_pred[:,0])),tf.maximum(epsilon(),n_y_false))\n",
    "\n",
    "def custom_loss(y_true,y_pred):\n",
    "# Weighted binary cross entropy loss\n",
    "  sh=tf.shape(y_pred)\n",
    "  nvals=tf.size(y_pred)\n",
    "\n",
    "  y_pred = tf.reshape(y_pred, [nvals,1])\n",
    "  y_true = tf.reshape(y_true, [nvals,1])\n",
    "\n",
    "  y_log_pred_t = tf.math.log(clip(y_pred, epsilon(), 9999.0))\n",
    "  y_log_pred_f = tf.math.log(clip(1.0-y_pred, epsilon(), 9999.0))\n",
    "  #n_y_true = tf.divide(tf.reduce_sum(y_true),tf.cast(nvals,tf.float32))\n",
    "  #n_y_false = 1.0 - n_y_true\n",
    "\n",
    "  n_y_false = 2.0 # Add weight to plant classes.\n",
    "  n_y_true = 1.0\n",
    "\n",
    "  return -tf.divide(tf.reduce_sum(n_y_false * y_log_pred_t * y_true + n_y_true * y_log_pred_f * (1.0-y_true)),tf.cast(nvals,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "3LtTqSnU4v6K",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=custom_loss, metrics=[custom_accuracy_p,custom_accuracy_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AWS CLI\n",
    "! pip install awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy image, masks, and test chips from S3\n",
    "# Note that the /scratch directory is the fast local storage in EarthAI Notebook - best place to temporarily store\n",
    "# image chips for deep learning; these data do NOT persist between sessions\n",
    "! aws s3 cp s3://sfi-shared-assets/cement-microloc-phase1 /scratch/cement-microloc-phase1 --recursive --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "k5vwCz3xqDYE",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6 # Limitations of Colab (free license).\n",
    "USE_STORED_MODEL = False # Change to True to use saved model.\n",
    "\n",
    "training_images = r'/scratch/cement-microloc-phase1/images'\n",
    "training_masks = r'/scratch/cement-microloc-phase1/masks'\n",
    "\n",
    "if not 'model' in os.listdir('/scratch/cement-microloc-phase1'):\n",
    "    os.mkdir(r'/scratch/cement-microloc-phase1/model')\n",
    "model_path = r'/scratch/cement-microloc-phase1/model/cement_model.h5'\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(model_path,\n",
    "                                           monitor='val_loss',\n",
    "                                           save_best_only=True,\n",
    "                                           save_weights_only=True,\n",
    "                                           verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, monitor='loss')]\n",
    "\n",
    "# generators for data augmentation -------\n",
    "seed = 1\n",
    "images_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=180,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect',\n",
    "    validation_split=0.2)\n",
    "\n",
    "masks_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=180,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect',\n",
    "    validation_split=0.2)\n",
    "\n",
    "image_generator = images_datagen.flow_from_directory(\n",
    "    training_images,\n",
    "    target_size=(IMG_WIDTH,IMG_HEIGHT),\n",
    "    class_mode=None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    training_masks,\n",
    "    target_size=(IMG_WIDTH,IMG_HEIGHT),\n",
    "    class_mode=None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    color_mode = 'grayscale',\n",
    "    seed=seed)\n",
    "\n",
    "val_image_generator = images_datagen.flow_from_directory(\n",
    "    training_images,\n",
    "    target_size=(IMG_WIDTH,IMG_HEIGHT),\n",
    "    class_mode=None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_mask_generator = masks_datagen.flow_from_directory(\n",
    "    training_masks,\n",
    "    target_size=(IMG_WIDTH,IMG_HEIGHT),\n",
    "    class_mode=None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    color_mode = 'grayscale',\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(val_image_generator, val_mask_generator)\n",
    "\n",
    "if USE_STORED_MODEL:\n",
    "  model.load_weights(model_path)\n",
    "else:\n",
    "  model.fit(train_generator, validation_data=validation_generator, \n",
    "            steps_per_epoch=len(training_images)//BATCH_SIZE, \n",
    "            validation_steps=len(training_images)//BATCH_SIZE,\n",
    "            epochs=50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "c92D1T2JCIk1",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix pretty print\n",
    "\n",
    "def print_cm(cm, labels):\n",
    "  print()\n",
    "  print(\"    t/p\", end=\" \")\n",
    "    \n",
    "  for label in labels:\n",
    "    print(\"%{0}s\".format(26) % label, end=\" \")\n",
    "    print(\"        \", end=\" \") \n",
    "  print()\n",
    "  # Print rows\n",
    "  for i, label1 in enumerate(labels):\n",
    "    print(\"%{0}s\".format(7) % label1, end=\" \")\n",
    "    for j in range(len(labels)):\n",
    "      frac = 100.0*cm[i,j]/np.sum(cm[i,:])\n",
    "      print(\"%{0}.d   \".format(20) % cm[i,j], end=\" \")\n",
    "      print(\"(%{0}.2f%%)\".format(6) % frac, end=\" \")\n",
    "    print()\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "c-L0nx9TvUY0",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "all_aoi_files = glob.glob(r'/scratch/cement-microloc-phase1/test/CHN*.jpg')\n",
    "\n",
    "if not 'plots' in os.listdir('/scratch/cement-microloc-phase1'):\n",
    "    os.mkdir(r'/scratch/cement-microloc-phase1/plots')\n",
    "for filen in range(len(all_aoi_files)):\n",
    "  aoi_file=all_aoi_files[filen]\n",
    "  mask_file = str.replace(aoi_file,'test/CHN','test/mask_CHN')\n",
    "\n",
    "  print(aoi_file)\n",
    "\n",
    "  aoi = plt.imread(aoi_file)\n",
    "  aoi = aoi/255\n",
    "  mask = plt.imread(mask_file)\n",
    "  mask = mask/255\n",
    "  preds_test = np.squeeze(model.predict(np.expand_dims(aoi.astype(float),axis = 0)))\n",
    "\n",
    "  f = plt.figure(figsize=[60,60])\n",
    "  f.add_subplot(3,3,1) \n",
    "  plt.imshow(aoi)\n",
    "  plt.title('Chip',fontsize = 80)\n",
    "  f.add_subplot(3,3,2) \n",
    "  plt.imshow(mask, cmap='gray')\n",
    "  plt.title('Mask',fontsize = 80)\n",
    "  f.add_subplot(3,3,3) \n",
    "  plt.imshow(preds_test, cmap='gray')\n",
    "  for i in range(7):\n",
    "    f.add_subplot(3,3,i+3) \n",
    "    pr = 0.1*(i+2)\n",
    "    preds_test_t = (preds_test > pr).astype(np.uint8)\n",
    "    plt.imshow(np.squeeze(preds_test_t), cmap='gray')\n",
    "    plt.title('pr(plant) > ' + str(np.round(pr,1)),fontsize = 80)\n",
    "    print_cm(confusion_matrix(np.uint8(mask.flatten()),\n",
    "                              preds_test_t.flatten(),\n",
    "                              labels=[0,1]),\n",
    "             ['backg','plant'])\n",
    " # plt.show()\n",
    "\n",
    "  out_file=r'/scratch/cement-microloc-phase1/plots/plot_' + str(filen) + '.jpg'\n",
    "  plt.savefig(out_file)\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model in S3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('sfi-shared-assets')\n",
    "\n",
    "bucket.upload_file(r'/scratch/cement-microloc-phase1/model/cement_model.h5', \\\n",
    "                   'cement-microloc-phase1/model/cement_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store generated plots in S3\n",
    "plots_list = os.listdir(r'/scratch/cement-microloc-phase1/plots')\n",
    "\n",
    "# Upload plot jpgs to s3\n",
    "for img in plots_list:\n",
    "    if re.search(\"CHN\", img):\n",
    "        bucket.upload_file(r'/scratch/cement-microloc-phase1/plots/'+img, \\\n",
    "                           'cement-microloc-phase1/plots/'+img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cement_unet_vgg16_aug_api.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EarthAI Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
